{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83e\uddea Lab 1 \u2014 Automated Experiments: GAN & VAE\n",
    "\n",
    "This notebook automates the training of GAN and VAE models with various hyperparameters. Results are saved to an Excel file and images are stored locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install necessary packages\n",
    "!pip install -q pandas openpyxl scipy matplotlib torch torchvision tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from scipy import linalg\n",
    "\n",
    "# Configuration\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Create directories for results\n",
    "os.makedirs('results/images', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data Loading\n",
    "def get_dataloader(batch_size):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    # Using FashionMNIST as default\n",
    "    train_ds = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test_ds  = datasets.FashionMNIST(root='./data',  train=False, download=True, transform=transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Models ---\n",
    "\n",
    "# GAN Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, img_ch=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(z_dim, 128*7*7),\n",
    "            nn.BatchNorm1d(128*7*7),\n",
    "            nn.ReLU(True),\n",
    "            nn.Unflatten(1, (128, 7, 7)),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, img_ch, 3, 1, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, z): return self.net(z)\n",
    "\n",
    "# GAN Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_ch=1):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(img_ch, 32, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(32, 64, 4, 2, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(64, 128, 3, 2, 1),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(nn.Flatten(), nn.Linear(128*4*4, 1))\n",
    "    def forward(self, x):\n",
    "        f = self.features(x)\n",
    "        return self.classifier(f).squeeze(1), f\n",
    "\n",
    "# VAE\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 4, 2, 1), nn.ReLU(True),\n",
    "            nn.Conv2d(32, 64, 4, 2, 1), nn.ReLU(True),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.enc_fc_mu = nn.Linear(64*7*7, latent)\n",
    "        self.enc_fc_log = nn.Linear(64*7*7, latent)\n",
    "        self.dec_fc = nn.Linear(latent, 64*7*7)\n",
    "        self.dec = nn.Sequential(\n",
    "            nn.Unflatten(1, (64, 7, 7)),\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 16, 4, 2, 1), nn.ReLU(True),\n",
    "            nn.Conv2d(16, 1, 3, 1, 1), nn.Tanh()\n",
    "        )\n",
    "    def encode(self, x):\n",
    "        h = self.enc(x)\n",
    "        return self.enc_fc_mu(h), self.enc_fc_log(h)\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = (0.5*logvar).exp()\n",
    "        return mu + torch.randn_like(std) * std\n",
    "    def decode(self, z): return self.dec(self.dec_fc(z))\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Metrics ---\n",
    "def gaussian_stats(X):\n",
    "    mu = X.mean(axis=0)\n",
    "    sigma = np.cov(X, rowvar=False)\n",
    "    return mu, sigma\n",
    "\n",
    "def frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
    "    diff = mu1 - mu2\n",
    "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
    "    if not np.isfinite(covmean).all():\n",
    "        covmean = linalg.sqrtm((sigma1 + np.eye(sigma1.shape[0])*eps).dot(sigma2 + np.eye(sigma2.shape[0])*eps))\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    fid = diff.dot(diff) + np.trace(sigma1 + sigma2 - 2*covmean)\n",
    "    return float(fid)\n",
    "\n",
    "def compute_fid(generator, discriminator, test_loader, z_dim, device):\n",
    "    discriminator.eval()\n",
    "    generator.eval()\n",
    "    \n",
    "    # Real features\n",
    "    real_feats = []\n",
    "    with torch.no_grad():\n",
    "        for i, (x, _) in enumerate(test_loader):\n",
    "            if i >= 50: break\n",
    "            x = x.to(device)\n",
    "            _, f = discriminator(x)\n",
    "            f = F.adaptive_avg_pool2d(f, 1).flatten(1)\n",
    "            real_feats.append(f.cpu())\n",
    "    real_feats = torch.cat(real_feats, dim=0).numpy()\n",
    "    \n",
    "    # Fake features\n",
    "    fake_feats = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(50):\n",
    "            z = torch.randn(128, z_dim, device=device)\n",
    "            x_fake = generator(z)\n",
    "            _, f = discriminator(x_fake)\n",
    "            f = F.adaptive_avg_pool2d(f, 1).flatten(1)\n",
    "            fake_feats.append(f.cpu())\n",
    "    fake_feats = torch.cat(fake_feats, dim=0).numpy()\n",
    "    \n",
    "    mu_r, sig_r = gaussian_stats(real_feats)\n",
    "    mu_g, sig_g = gaussian_stats(fake_feats)\n",
    "    return frechet_distance(mu_r, sig_r, mu_g, sig_g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Training Loops ---\n",
    "\n",
    "def run_gan_experiment(config, results_list):\n",
    "    z_dim = config['z_dim']\n",
    "    lr = config['lr']\n",
    "    batch_size = config['batch_size']\n",
    "    epochs = config['epochs']\n",
    "    \n",
    "    print(f\"Running GAN: Z_DIM={z_dim}, LR={lr}, Batch={batch_size}\")\n",
    "    \n",
    "    train_loader, test_loader = get_dataloader(batch_size)\n",
    "    G = Generator(z_dim).to(DEVICE)\n",
    "    D = Discriminator().to(DEVICE)\n",
    "    opt_G = torch.optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    opt_D = torch.optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        G.train(); D.train()\n",
    "        for x, _ in tqdm(train_loader, leave=False):\n",
    "            x = x.to(DEVICE)\n",
    "            # Train D\n",
    "            z = torch.randn(x.size(0), z_dim, device=DEVICE)\n",
    "            x_fake = G(z).detach()\n",
    "            d_real, _ = D(x)\n",
    "            d_fake, _ = D(x_fake)\n",
    "            loss_d = F.relu(1.0 - d_real).mean() + F.relu(1.0 + d_fake).mean()\n",
    "            opt_D.zero_grad(); loss_d.backward(); opt_D.step()\n",
    "            \n",
    "            # Train G\n",
    "            z = torch.randn(x.size(0), z_dim, device=DEVICE)\n",
    "            d_fake, _ = D(G(z))\n",
    "            loss_g = -d_fake.mean()\n",
    "            opt_G.zero_grad(); loss_g.backward(); opt_G.step()\n",
    "            \n",
    "    # Evaluation\n",
    "    fid = compute_fid(G, D, test_loader, z_dim, DEVICE)\n",
    "    \n",
    "    # Save Image\n",
    "    z = torch.randn(64, z_dim, device=DEVICE)\n",
    "    img = G(z).cpu()\n",
    "    img_filename = f\"GAN_Z{z_dim}_LR{lr}_B{batch_size}.png\"\n",
    "    utils.save_image(img, f\"results/images/{img_filename}\", normalize=True, value_range=(-1,1), nrow=8)\n",
    "    \n",
    "    results_list.append({\n",
    "        'Model': 'GAN',\n",
    "        'Z_DIM/Latent': z_dim,\n",
    "        'LR': lr,\n",
    "        'Batch Size': batch_size,\n",
    "        'Epochs': epochs,\n",
    "        'FID': fid,\n",
    "        'Image File': img_filename\n",
    "    })\n",
    "\n",
    "def run_vae_experiment(config, results_list):\n",
    "    latent = config['latent']\n",
    "    lr = config['lr']\n",
    "    batch_size = config['batch_size']\n",
    "    epochs = config['epochs']\n",
    "    \n",
    "    print(f\"Running VAE: Latent={latent}, LR={lr}, Batch={batch_size}\")\n",
    "    \n",
    "    train_loader, test_loader = get_dataloader(batch_size)\n",
    "    vae = VAE(latent).to(DEVICE)\n",
    "    opt = torch.optim.Adam(vae.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        vae.train()\n",
    "        for x, _ in tqdm(train_loader, leave=False):\n",
    "            x = x.to(DEVICE)\n",
    "            xhat, mu, logvar = vae(x)\n",
    "            recon = F.l1_loss(xhat, x, reduction='sum') / x.size(0)\n",
    "            kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / x.size(0)\n",
    "            loss = recon + kl\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            \n",
    "    # Save Image (Reconstruction)\n",
    "    x = next(iter(test_loader))[0][:32].to(DEVICE)\n",
    "    xhat, _, _ = vae(x)\n",
    "    combined = torch.cat([x, xhat], dim=0)\n",
    "    img_filename = f\"VAE_L{latent}_LR{lr}_B{batch_size}.png\"\n",
    "    utils.save_image(combined, f\"results/images/{img_filename}\", normalize=True, value_range=(-1,1), nrow=8)\n",
    "    \n",
    "    results_list.append({\n",
    "        'Model': 'VAE',\n",
    "        'Z_DIM/Latent': latent,\n",
    "        'LR': lr,\n",
    "        'Batch Size': batch_size,\n",
    "        'Epochs': epochs,\n",
    "        'FID': 'N/A', # FID for VAE vs Real is possible but skipping for speed/simplicity unless requested\n",
    "        'Image File': img_filename\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Run All Experiments ---\n",
    "results = []\n",
    "\n",
    "# GAN Configurations\n",
    "gan_configs = [\n",
    "    {'z_dim': 32, 'lr': 2e-4, 'batch_size': 128, 'epochs': 5},\n",
    "    {'z_dim': 64, 'lr': 2e-4, 'batch_size': 128, 'epochs': 5},\n",
    "    {'z_dim': 128, 'lr': 2e-4, 'batch_size': 128, 'epochs': 5},\n",
    "    {'z_dim': 64, 'lr': 1e-4, 'batch_size': 128, 'epochs': 5}, # Lower LR\n",
    "    {'z_dim': 64, 'lr': 2e-4, 'batch_size': 64, 'epochs': 5},  # Smaller Batch\n",
    "]\n",
    "\n",
    "# VAE Configurations\n",
    "vae_configs = [\n",
    "    {'latent': 8, 'lr': 2e-3, 'batch_size': 128, 'epochs': 5},\n",
    "    {'latent': 16, 'lr': 2e-3, 'batch_size': 128, 'epochs': 5},\n",
    "    {'latent': 32, 'lr': 2e-3, 'batch_size': 128, 'epochs': 5},\n",
    "]\n",
    "\n",
    "print(\"Starting GAN Experiments...\")\n",
    "for conf in gan_configs:\n",
    "    run_gan_experiment(conf, results)\n",
    "\n",
    "print(\"Starting VAE Experiments...\")\n",
    "for conf in vae_configs:\n",
    "    run_vae_experiment(conf, results)\n",
    "\n",
    "# Save to Excel\n",
    "df = pd.DataFrame(results)\n",
    "df.to_excel(\"results/experiment_results.xlsx\", index=False)\n",
    "print(\"Experiments completed! Results saved to results/experiment_results.xlsx\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Zip results for download (if in Colab)\n",
    "!zip -r results.zip results/\n",
    "from google.colab import files\n",
    "files.download('results.zip')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Lab1_Automated_Experiments.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}